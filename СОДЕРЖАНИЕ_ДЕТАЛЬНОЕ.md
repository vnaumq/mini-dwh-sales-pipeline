# ДЕТАЛЬНОЕ СОДЕРЖАНИЕ КУРСОВОЙ РАБОТЫ

## "АВТОМАТИЗАЦИЯ ПРОЦЕССА СБОРА ДАННЫХ ИНТЕРНЕТ-МАГАЗИНА"

---

## ВВЕДЕНИЕ

**Объем: 2-3 страницы**

- Актуальность темы исследования
- Цель курсовой работы
- Задачи исследования
- Объект и предмет исследования
- Методы исследования
- Практическая значимость работы
- Структура работы

---

## 1. ТЕОРЕТИЧЕСКИЕ ОСНОВЫ АВТОМАТИЗАЦИИ СБОРА ДАННЫХ ИНТЕРНЕТ-МАГАЗИНОВ

**Объем: 15-20 страниц**

### 1.1. Понятие и сущность автоматизации сбора данных интернет-магазинов

- Определение автоматизации сбора данных
- Преимущества автоматизации перед ручным сбором
- Области применения автоматизированного сбора данных
- Проблемы и вызовы при автоматизации сбора данных
- Правовые аспекты сбора данных

### 1.2. Методы и технологии сбора данных из веб-источников

#### 1.2.1. Web Scraping и парсинг веб-страниц

- Основные принципы веб-скрапинга
- Инструменты для парсинга (BeautifulSoup, Scrapy, lxml)
- Обработка динамического контента
- Ограничения и этические вопросы

#### 1.2.2. Работа с REST API и GraphQL

- REST API: принципы работы, методы HTTP
- GraphQL: особенности и преимущества
- Аутентификация в API (OAuth, API keys, cookies)
- Обработка rate limiting и квот

#### 1.2.3. Автоматизация браузера с использованием Selenium

- Принципы работы Selenium
- Selenium WebDriver и его возможности
- Headless-режим браузера
- Selenium Grid для распределенной работы
- Альтернативы Selenium (Playwright, Puppeteer)

### 1.3. ETL-процессы в контексте сбора данных

#### 1.3.1. Этапы ETL: Extract, Transform, Load

- **Extract (Извлечение)**: методы извлечения данных
- **Transform (Трансформация)**: очистка, валидация, нормализация
- **Load (Загрузка)**: стратегии загрузки данных
- ETL vs ELT подходы

#### 1.3.2. Оркестрация ETL-процессов

- Понятие оркестрации данных
- Планирование и мониторинг задач
- Обработка зависимостей между задачами
- Управление ошибками и повторные попытки

### 1.4. Хранилища данных для аналитики интернет-магазинов

#### 1.4.1. Data Warehouse и Data Lake

- Концепция Data Warehouse
- Data Lake и его особенности
- Сравнение подходов
- Выбор подходящего решения

#### 1.4.2. Реляционные и NoSQL базы данных

- Реляционные БД (PostgreSQL, MySQL) для структурированных данных
- NoSQL БД (MongoDB, Cassandra) для неструктурированных данных
- Объектные хранилища (S3, MinIO) для файлов
- Выбор типа хранилища в зависимости от задачи

---

## 2. АНАЛИЗ СУЩЕСТВУЮЩИХ РЕШЕНИЙ И ВЫБОР ТЕХНОЛОГИЙ

**Объем: 12-15 страниц**

### 2.1. Анализ платформы eggheads.solutions как источника данных

#### 2.1.1. Структура данных и API платформы

- Описание платформы eggheads.solutions
- Анализ доступных эндпоинтов API
- Структура ответов API
- Требования к аутентификации
- Ограничения и лимиты API

#### 2.1.2. Типы собираемых данных: категории, продажи, товары

- **Иерархия категорий**: L1, L2, L3 категории товаров
- **Аналитика продаж**: данные за 30 дней, тренды, метрики
- **Данные о товарах**: рейтинги, позиции, характеристики
- **Сезонность**: коэффициенты сезонности для прогнозирования

### 2.2. Сравнительный анализ инструментов оркестрации данных

#### 2.2.1. Apache Airflow: возможности и преимущества

- История и развитие Apache Airflow
- Основные компоненты (Scheduler, Executor, Web UI)
- Концепция DAG (Directed Acyclic Graph)
- Преимущества для ETL-процессов
- Недостатки и ограничения

#### 2.2.2. Альтернативные решения (Apache NiFi, Prefect, Dagster)

- **Apache NiFi**: визуальный интерфейс, потоковая обработка
- **Prefect**: современный подход, Python-first
- **Dagster**: управление данными как код
- Сравнительная таблица по критериям:
  - Простота использования
  - Производительность
  - Масштабируемость
  - Сообщество и поддержка

### 2.3. Выбор технологического стека

#### 2.3.1. Обоснование выбора Apache Airflow 3.0.4

- Причины выбора Apache Airflow
- Преимущества версии 3.0.4
- Интеграция с другими компонентами системы

#### 2.3.2. Выбор систем хранения данных (PostgreSQL, MinIO)

- **PostgreSQL**: выбор для реляционных данных
- **MinIO**: выбор для промежуточного хранения файлов
- Обоснование выбора каждой системы

#### 2.3.3. Инструменты визуализации (Apache Superset)

- Возможности Apache Superset
- Интеграция с PostgreSQL
- Создание дашбордов и визуализаций

---

## 3. ПРОЕКТИРОВАНИЕ СИСТЕМЫ АВТОМАТИЗАЦИИ СБОРА ДАННЫХ

**Объем: 15-18 страниц**

### 3.1. Архитектура системы

#### 3.1.1. Общая архитектура решения

- Высокоуровневая архитектура системы
- Компоненты и их назначение
- Принципы проектирования (микросервисы, контейнеризация)

#### 3.1.2. Компоненты системы и их взаимодействие

- **Apache Airflow**: оркестрация процессов
- **PostgreSQL**: основное хранилище данных
- **MinIO**: промежуточное хранилище файлов
- **Selenium Grid**: автоматизация браузера
- **Apache Superset**: визуализация данных
- Схема взаимодействия компонентов

#### 3.1.3. Поток данных от источника до визуализации

- Детальное описание потока данных:
  1. Аутентификация через Selenium
  2. Извлечение данных через API
  3. Сохранение в MinIO
  4. Загрузка в PostgreSQL
  5. Визуализация в Superset

### 3.2. Проектирование ETL-пайплайна

#### 3.2.1. Этап Extract: извлечение данных из API

- Процесс аутентификации
- Получение cookies через Selenium
- Структура запросов к API
- Обработка различных типов данных

#### 3.2.2. Этап Transform: обработка и нормализация данных

- Очистка данных
- Нормализация JSON-структур
- Преобразование типов данных
- Создание связей между сущностями

#### 3.2.3. Этап Load: загрузка в хранилище данных

- Стратегия загрузки (append, replace, upsert)
- Загрузка в MinIO (CSV файлы)
- Загрузка в PostgreSQL (таблицы)
- Обработка конфликтов и дубликатов

### 3.3. Проектирование схемы базы данных

#### 3.3.1. Модель данных для категорий товаров (L1, L2, L3)

- ER-диаграмма категорий
- Таблицы: category_l1_l2, category_l3
- Связи между уровнями категорий
- Индексы для оптимизации запросов

#### 3.3.2. Модель данных для аналитики продаж

- Таблица: category_info_days
- Поля: дата, категория, метрики продаж
- Временные ряды и их особенности
- Агрегация данных

#### 3.3.3. Модель данных для товаров и сезонности

- Таблицы: info_subjects, info_subjects_days, season_ratio
- Связи между товарами и категориями
- Хранение коэффициентов сезонности

### 3.4. Проектирование процессов аутентификации и авторизации

#### 3.4.1. Механизм получения cookies через Selenium

- Процесс автоматического входа
- Извлечение cookies из браузера
- Передача cookies в HTTP-запросах
- Обновление cookies при истечении

#### 3.4.2. Управление сессиями и обработка ошибок

- Управление жизненным циклом сессий
- Обработка ошибок аутентификации
- Retry-логика для повторных попыток
- Логирование и мониторинг

---

## 4. РЕАЛИЗАЦИЯ СИСТЕМЫ АВТОМАТИЗАЦИИ СБОРА ДАННЫХ

**Объем: 20-25 страниц**

### 4.1. Настройка инфраструктуры

#### 4.1.1. Развертывание Docker-контейнеров

- Docker Compose конфигурация
- Описание сервисов и их зависимостей
- Настройка сетей и volumes
- Переменные окружения

#### 4.1.2. Конфигурация Apache Airflow

- Настройка airflow.cfg
- Конфигурация Executor (LocalExecutor)
- Настройка подключений к БД
- Настройка логирования

#### 4.1.3. Настройка PostgreSQL и MinIO

- Инициализация схемы БД
- Создание bucket в MinIO
- Настройка прав доступа
- Резервное копирование

### 4.2. Реализация модуля аутентификации

#### 4.2.1. Интеграция с Selenium Grid

- Подключение к удаленному Selenium
- Настройка Chrome options для headless-режима
- Обработка ошибок подключения

#### 4.2.2. Функции получения и управления cookies

- Функция `get_cookies()`: автоматический вход
- Извлечение cookies из браузера
- Форматирование cookies для requests/aiohttp
- Кэширование cookies

### 4.3. Реализация DAG-ов для сбора данных

#### 4.3.1. DAG для сбора иерархии категорий (get_l1_l2_dag, get_l3_dag)

- Структура DAG
- Функции извлечения данных (`get_l1_l2`, `get_l3`)
- Обработка JSON-ответов
- Сохранение в MinIO

#### 4.3.2. DAG для сбора аналитики продаж (get_info_30_days_dag)

- Параметры запроса (дата, период, фильтры)
- Функция `get_info_30_days()`
- Обработка трендов и метрик
- Нормализация данных с pandas

#### 4.3.3. DAG для сбора данных о товарах (get_info_subjects_dag)

- Получение рейтинга товаров
- Сбор аналитики по товарам за 30 дней
- Обработка больших объемов данных

#### 4.3.4. DAG для сбора коэффициентов сезонности (get_season_ratio_dag)

- Запрос коэффициентов для товаров
- Обработка временных рядов
- Сохранение данных о сезонности

### 4.4. Реализация асинхронной обработки данных

#### 4.4.1. Использование aiohttp для параллельных запросов

- Преимущества асинхронного подхода
- Создание ClientSession
- Параллельные запросы к API
- Сравнение производительности

#### 4.4.2. Обработка rate limiting и экспоненциальный backoff

- Обнаружение ошибки 429 (Too Many Requests)
- Реализация экспоненциального backoff
- Максимальное количество попыток
- Логирование повторных попыток

#### 4.4.3. Оптимизация производительности с использованием семафоров

- Контроль параллельности запросов
- Использование asyncio.Semaphore
- Балансировка нагрузки на API
- Оптимальное количество одновременных запросов

### 4.5. Реализация модуля загрузки данных в хранилище

#### 4.5.1. Сохранение промежуточных данных в MinIO

- Использование boto3 для работы с MinIO
- Загрузка CSV файлов в bucket
- Организация файлов по датам
- Обработка ошибок загрузки

#### 4.5.2. Загрузка данных в PostgreSQL (loading_data_to_postgres_dag)

- Чтение CSV из MinIO
- Преобразование данных с pandas
- Использование SQLAlchemy для загрузки
- Стратегии загрузки (replace, append)

#### 4.5.3. Обработка ошибок и валидация данных

- Валидация типов данных
- Проверка обязательных полей
- Обработка дубликатов
- Логирование ошибок

### 4.6. Настройка визуализации в Apache Superset

#### 4.6.1. Подключение к PostgreSQL

- Настройка database connection
- Создание схемы и таблиц в Superset
- Настройка прав доступа

#### 4.6.2. Создание дашбордов для анализа продаж

- Создание charts (графики, таблицы)
- Анализ трендов продаж
- Сравнение категорий
- Анализ сезонности

---

## 5. ТЕСТИРОВАНИЕ И ОПТИМИЗАЦИЯ СИСТЕМЫ

**Объем: 12-15 страниц**

### 5.1. Тестирование функциональности системы

#### 5.1.1. Тестирование модуля аутентификации

- Тестирование получения cookies
- Проверка валидности cookies
- Тестирование обработки ошибок
- Тесты для различных сценариев

#### 5.1.2. Тестирование DAG-ов и обработки данных

- Unit-тесты для функций извлечения данных
- Интеграционные тесты для DAG-ов
- Проверка корректности данных
- Тестирование обработки ошибок

#### 5.1.3. Тестирование загрузки данных в хранилище

- Тестирование загрузки в MinIO
- Тестирование загрузки в PostgreSQL
- Проверка целостности данных
- Тестирование производительности

### 5.2. Анализ производительности

#### 5.2.1. Сравнение синхронной и асинхронной обработки

- Метрики времени выполнения
- Сравнение использования ресурсов
- Анализ пропускной способности
- Выводы и рекомендации

#### 5.2.2. Метрики времени выполнения задач

- Время выполнения каждого DAG
- Анализ узких мест (bottlenecks)
- Зависимости между задачами
- Оптимизация критического пути

#### 5.2.3. Анализ использования ресурсов

- Использование CPU и памяти
- Нагрузка на сеть
- Использование дискового пространства
- Рекомендации по масштабированию

### 5.3. Оптимизация системы

#### 5.3.1. Оптимизация запросов к API

- Кэширование данных
- Батчинг запросов
- Оптимизация параметров запросов
- Снижение количества запросов

#### 5.3.2. Оптимизация работы с базой данных

- Создание индексов
- Оптимизация запросов SQL
- Партиционирование таблиц
- Настройка параметров PostgreSQL

#### 5.3.3. Улучшение обработки ошибок и надежности

- Улучшение retry-логики
- Добавление алертов
- Мониторинг состояния системы
- Автоматическое восстановление после сбоев

---

## ЗАКЛЮЧЕНИЕ

**Объем: 2-3 страницы**

- Краткое резюме выполненной работы
- Достигнутые цели и задачи
- Основные результаты исследования
- Практическая значимость работы
- Возможности дальнейшего развития системы
- Выводы по работе

---

## СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ

**Объем: 2-3 страницы**

- Книги и учебные пособия
- Научные статьи
- Официальная документация технологий
- Онлайн-ресурсы и блоги
- ГОСТы и стандарты (если применимо)

**Примеры источников:**
1. Apache Airflow Documentation. URL: https://airflow.apache.org/docs/
2. PostgreSQL Documentation. URL: https://www.postgresql.org/docs/
3. Selenium Documentation. URL: https://www.selenium.dev/documentation/
4. И другие источники...

---

## ПРИЛОЖЕНИЯ

### Приложение А. Конфигурационные файлы проекта

- docker-compose.yaml
- airflow.cfg
- .env.example
- requirements.txt

### Приложение Б. Примеры кода DAG-ов

- get_l1_l2_dag.py
- get_info_30_days_async_dag.py
- loading_data_to_postgres_dag.py
- endpoints.py (ключевые функции)

### Приложение В. Схема базы данных

- ER-диаграмма
- SQL-скрипты создания таблиц
- Описание таблиц и связей

### Приложение Г. Скриншоты интерфейсов системы

- Airflow UI (список DAG-ов, график выполнения)
- Superset (дашборды)
- pgAdmin (структура БД)
- MinIO Console (файлы)

---

**Общий объем курсовой работы: 80-100 страниц**

**Рекомендации по оформлению:**
- Шрифт: Times New Roman, 14pt
- Межстрочный интервал: 1.5
- Поля: левое 30мм, остальные 20мм
- Нумерация страниц: внизу по центру
- Ссылки на источники в квадратных скобках [1]
